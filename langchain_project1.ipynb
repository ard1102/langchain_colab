{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PlnpgU4d5Cl",
        "outputId": "04f8f610-1de7-4cc7-87a2-cd406b9a5b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallaion successful\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain openai streamlit python-dotenv langchain_community -q\n",
        "\n",
        "print('Installaion successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads any existing .env variables.\n",
        "\n",
        "Compares them to your desired list (env_keys).\n",
        "\n",
        "If any are missing but exist in the system environment, it appends them to the file."
      ],
      "metadata": {
        "id": "gJJnGtach5f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd\n",
        "! ls\n",
        "! ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4-pr7biRf2",
        "outputId": "4309fcf1-d6f9-43cc-e3f4-479f690e8037"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n",
            ".  ..  .config\t.env  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env file handel\n",
        "import os\n",
        "\n",
        "env_file = \".env\"\n",
        "env_keys = [\"API_KEY\", \"DATABASE_URL\", \"SECRET_KEY\"]  # Customize this list\n",
        "\n",
        "existing_vars = {}\n",
        "\n",
        "# Load existing variables if file exists\n",
        "if os.path.exists(env_file):\n",
        "    with open(env_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line and not line.startswith(\"#\") and \"=\" in line:\n",
        "                key, val = line.split(\"=\", 1)\n",
        "                existing_vars[key.strip()] = val.strip()\n",
        "    print(f\"Loaded existing variables from {env_file}.\")\n",
        "else:\n",
        "    # Create the file if it doesn't exist\n",
        "    with open(env_file, \"w\") as f:\n",
        "        f.write(\"\")  # Create an empty file\n",
        "    print(f\"Created new {env_file} file.\")\n",
        "\n",
        "# Collect missing vars\n",
        "new_vars = {}\n",
        "for key in env_keys:\n",
        "    if key not in existing_vars:\n",
        "        value = os.getenv(key)\n",
        "        if not value:\n",
        "            # Optional: prompt the user for a value if it's missing\n",
        "            value = input(f\"Enter value for {key}: \").strip()\n",
        "        if value:\n",
        "            new_vars[key] = value\n",
        "\n",
        "# Write new vars to file\n",
        "if new_vars:\n",
        "    with open(env_file, \"a\") as f:\n",
        "        for key, value in new_vars.items():\n",
        "            f.write(f\"{key}={value}\\n\")\n",
        "    print(f\"Added to {env_file}: {', '.join(new_vars.keys())}\")\n",
        "else:\n",
        "    print(\"No new variables to add.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5moxcbwhwuS",
        "outputId": "49b95d58-be1c-4d21-b1b0-3298ced248f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded existing variables from .env.\n",
            "No new variables to add.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"API_KEY\")\n",
        "api_base = os.getenv(\"DATABASE_URL\")\n",
        "\n",
        "model1=\"deepseek/deepseek-chat-v3-0324:free\"\n",
        "model2=\"google/gemini-2.5-pro-exp-03-25:free\"\n",
        "model3=\"deepseek/deepseek-r1:free\"\n",
        "model4=\"deepseek/deepseek-r1-zero:free\"\n",
        "def generate_pet_name():\n",
        "  # llm = OpenAI(openai_api_key=api_key,openai_api_base=api_base,temperature=0.7)\n",
        "  # prompt=\"I have a dog pet and I want a cool anme for it. Suggest me five cool names for my pet.\"\n",
        "  # name= llm(prompt)\n",
        "  # return name\n",
        "  llm=ChatOpenAI( openai_api_key=api_key, openai_api_base=api_base,model_name=model2,temperature=0.7)\n",
        "  prompt=messages = [HumanMessage(content=\"I have a dog pet and I want a cool anme for it. Suggest me five cool names for my pet.\")]\n",
        "  name=llm(prompt)\n",
        "  return name\n",
        "\n",
        "\n",
        "if __name__ ==\"__main__\":\n",
        "  print(generate_pet_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd7QFAhxft8r",
        "outputId": "4c06de64-71f3-4d65-b360-ab5f7eb81a18"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Okay, here are five cool name suggestions for your dog, hitting a few different styles:\\n\\n1.  **Maverick:** Sounds independent, adventurous, and a bit rebellious. Popularized by *Top Gun*, it has a strong, confident feel.\\n2.  **Zephyr:** Unique and sounds sleek (it means a gentle breeze). It has a cool, almost ethereal vibe but is still easy to say.\\n3.  **Atlas:** Strong, grounded, and carries a bit of weight (from the mythological Titan who held up the sky). It sounds significant and dependable.\\n4.  **Onyx:** Named after the black gemstone, this sounds sleek, cool, and a little mysterious. Especially great for a dark-coated dog, but cool for any.\\n5.  **Jax:** Short, punchy, and has a modern, slightly edgy feel. It's energetic and easy to call out.\\n\\n**Bonus Tip:** Try saying the names out loud as if you were calling your dog. See which one feels right and rolls off the tongue easily! Good luck choosing!\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 2439, 'prompt_tokens': 25, 'total_tokens': 1357, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'google/gemini-2.5-pro-exp-03-25:free', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-4ce6c2ed-2d50-4bbf-816d-f60d813c8d21-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gen.py\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"API_KEY\")\n",
        "api_base = os.getenv(\"DATABASE_URL\")\n",
        "\n",
        "model1=\"deepseek/deepseek-chat-v3-0324:free\"\n",
        "model2=\"google/gemini-2.5-pro-exp-03-25:free\"\n",
        "model3=\"deepseek/deepseek-r1:free\"\n",
        "model4=\"deepseek/deepseek-r1-zero:free\"\n",
        "\n",
        "def generate_pet_name(animal_type, pet_color):\n",
        "  # llm = OpenAI(openai_api_key=api_key,openai_api_base=api_base,temperature=0.7)\n",
        "  # prompt=\"I have a dog pet and I want a cool anme for it. Suggest me five cool names for my pet.\"\n",
        "  # name= llm(prompt)\n",
        "  # return name\n",
        "  llm=ChatOpenAI( openai_api_key=api_key, openai_api_base=api_base,model_name=model2,temperature=0.7)\n",
        "\n",
        "  prompt_template_name=PromptTemplate(\n",
        "      input_variables=['animal_type', 'pet_color'],\n",
        "      template=\"I have a {animal_type} pet and I wnat a col name for it, the color of my pet is {pet_color}. suggest me five cool names for my pet.\"\n",
        "  )\n",
        "\n",
        "  name_chain = LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"pet_name\")\n",
        "  response=name_chain({'animal_type':animal_type, 'pet_color':pet_color})\n",
        "  return response\n",
        "\n",
        "\n",
        "if __name__ ==\"__main__\":\n",
        "  print(generate_pet_name(\"cat\",\"brown\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzwhW4Gqhuy3",
        "outputId": "acacab47-6d44-47e4-eba8-6977551586f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gen.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tutorial for streamlit on colab (\"https://youtu.be/NEhrkeF2o_M?si=5AHh3xxhqGIDWXZd\")"
      ],
      "metadata": {
        "id": "hF81hkJ7TDt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import gen as g\n",
        "st.title(\"My pet name generator\")\n",
        "\n",
        "uanimal_type=st.sidebar.selectbox(\"What is your pet?\",(\"cat\",\"Dog\",\"cow\",\"Hamster\"))\n",
        "uanimal_color=st.sidebar.selectbox(\"what color is your \"+uanimal_type,(\"black\",\"brown\",\"white\",\"grey\"))\n",
        "\n",
        "if st.sidebar.button(\"Generate pet name\"):\n",
        "  response=g.generate_pet_name(uanimal_type,uanimal_color)\n",
        "  st.write(response['pet_name'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xciYoSDYIKf5",
        "outputId": "31ae268c-62d6-4d2f-b368-1ef29aea1796"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501 -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0vVCfF9K1qW",
        "outputId": "c7b04304-396f-49eb-f74a-fc80a9559318"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.194.137.139:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0Kyour url is: https://fifty-camels-allow.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/chat_models/__init__.py:33: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.chat_models import ChatOpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/content/gen.py:24: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm=ChatOpenAI( openai_api_key=api_key, openai_api_base=api_base,model_name=model2,temperature=0.7)\n",
            "/content/gen.py:31: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  name_chain = LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"pet_name\")\n",
            "/content/gen.py:32: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response=name_chain({'animal_type':animal_type, 'pet_color':pet_color})\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}